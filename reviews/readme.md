# Code Review Reports

This directory contains comprehensive code review reports generated by the `/review` Cursor command.

## Usage

### Basic Usage

```bash
# Full codebase review
/review full

# Review current changes
/review
```

### Scoped Reviews

```bash
# Review specific directory
/review internal/api

# Review specific file
/review cmd/dot/manage.go

# Review multiple paths
/review internal/api internal/executor

# Focus on specific concern
/review security
/review tests
/review documentation
```

## Report Format

Each review generates a timestamped markdown report:

```
code-review-YYYY-MM-DD_HHmmss.md
```

Example: `code-review-2025-10-06_143000.md`

## Report Structure

### 1. Executive Summary
High-level overview of code quality and key findings.

### 2. Quality Dashboard
Quick metrics view:
- Test coverage percentage
- Linting status
- Issue counts by severity
- Overall quality score

### 3. Top 5 Critical Issues
Most important issues requiring immediate attention.

### 4. Detailed Findings

Issues organized by severity:
- **Critical**: Must fix before release
- **High**: Should fix soon
- **Medium**: Improve when possible  
- **Low**: Optional improvements

Each issue includes:
- Unique ID with timestamp
- Category and severity
- Exact file locations
- Detailed description
- Impact explanation
- Constitutional principle violated
- Recommended resolution
- Code examples (current and expected)
- AI-executable remediation prompt
- Verification checklist

### 5. Remediation Plan

Issues grouped into logical batches:
- Ordered by dependencies
- Estimated effort
- Combined AI prompts
- Verification steps

### 6. Verification Checklist

Complete checklist for confirming all fixes are correct.

### 7. Appendix

Full tool outputs, coverage reports, and methodology.

## Review Dimensions

The review evaluates code across seven dimensions:

### 1. Constitutional Compliance
- Test-First Development (TDD)
- Atomic Commits
- Functional Programming Principles
- Standard Technology Stack
- Academic Documentation Standard
- Code Quality Gates

### 2. Architectural Compliance
- Layer Separation
- Functional Core, Imperative Shell
- Type Safety

### 3. Code Quality
- Error Handling
- Function Design
- Code Smells

### 4. Testing Quality
- Unit Test Coverage
- Test Quality
- Integration Tests

### 5. Security
- Input Validation
- File System Security
- Sensitive Data Handling
- Dependency Security

### 6. Documentation
- Code Documentation (godoc)
- Project Documentation

### 7. Performance
- Memory Efficiency
- Algorithm Efficiency

## Using AI Remediation Prompts

Each issue includes an AI-executable remediation prompt that can be:

1. **Copy-paste to Cursor**: Select the prompt and paste into a new chat
2. **Execute directly**: The prompt is self-contained with all context
3. **Batch execution**: Use the combined batch prompts for efficiency

### Example Workflow

```
1. Run review:
   /review full

2. Open generated report:
   reviews/code-review-2025-10-06_143000.md

3. Identify critical issues in Executive Summary

4. For each critical issue:
   a. Read the detailed finding
   b. Understand the impact
   c. Copy the AI Remediation Prompt
   d. Paste into new Cursor chat
   e. Let AI implement the fix
   f. Follow verification steps

5. After all fixes:
   - Run make check
   - Commit changes
   - Run review again to confirm
```

## Interpreting Severity Levels

### CRITICAL
- **Definition**: Issues that violate core principles or pose security risks
- **Action Required**: Fix immediately before any release
- **Examples**: 
  - Security vulnerabilities
  - Constitutional violations
  - Architectural boundary breaches
  - Untracked code files

### HIGH
- **Definition**: Issues that significantly impact quality or maintainability
- **Action Required**: Fix in current sprint or iteration
- **Examples**:
  - Missing tests for new code
  - Error handling violations
  - Test coverage below threshold
  - Missing documentation for public APIs

### MEDIUM
- **Definition**: Issues that should be improved but don't block progress
- **Action Required**: Incorporate into regular development workflow
- **Examples**:
  - Code smells (long functions, duplication)
  - Performance concerns
  - Documentation gaps
  - Refactoring opportunities

### LOW
- **Definition**: Minor improvements for polish and consistency
- **Action Required**: Fix opportunistically during related work
- **Examples**:
  - Import organization
  - Style inconsistencies
  - Minor documentation improvements
  - Comment updates

## Quality Score Calculation

Overall quality score (0-10) is calculated based on:

```
Base Score: 10.0

Deductions:
- Each CRITICAL issue: -1.0 point
- Each HIGH issue: -0.3 points
- Each MEDIUM issue: -0.1 points
- LOW issues: no deduction

Coverage adjustment:
- Coverage < 80%: -0.5 points
- Coverage < 70%: -1.0 points

Linting adjustment:
- Linting failures: -0.5 points

Minimum score: 0.0
Maximum score: 10.0
```

Target quality score: **8.0 or higher**

## Best Practices

### Regular Reviews

Run reviews regularly:
- Before creating PRs
- After completing features
- Before releases
- Weekly for active development
- After major refactoring

### Incremental Improvement

Don't try to fix everything at once:
1. Always fix CRITICAL issues first
2. Address HIGH issues before new features
3. Tackle MEDIUM issues in batches
4. Fix LOW issues opportunistically

### Track Progress

Keep review reports to track improvement over time:
```
reviews/
├── code-review-2025-09-01_100000.md  (baseline)
├── code-review-2025-09-15_140000.md  (after sprint 1)
├── code-review-2025-10-01_110000.md  (after sprint 2)
└── code-review-2025-10-06_143000.md  (current)
```

Compare metrics across reviews to measure quality trends.

### Integrate with Workflow

1. **Pre-commit**: Review your changes before committing
2. **Pre-PR**: Run full review before creating pull request
3. **Pre-release**: Comprehensive review before version tagging
4. **Post-merge**: Review to catch integration issues

## Automation

### Git Hooks

Add to `.git/hooks/pre-push`:
```bash
#!/bin/bash
echo "Running code review..."
# Trigger review command
# Block push if critical issues found
```

### CI Integration

Add to CI pipeline:
```yaml
- name: Code Review
  run: |
    # Generate review report
    # Parse for CRITICAL issues
    # Fail build if found
```

## Maintenance

### Report Retention

Keep reports for:
- **Current sprint**: All reports
- **Last 3 months**: Weekly reports
- **Historical**: Release milestone reports

Archive or delete older reports to manage disk space.

### Template Updates

The review report template may be updated to:
- Add new review dimensions
- Improve issue detection
- Enhance remediation prompts
- Update formatting

Check template version in report header.

## Troubleshooting

### Command Not Found

Ensure `.cursor/commands/review.md` exists and is properly formatted.

### Review Takes Too Long

For large codebases, scope reviews:
```bash
# Review specific areas
/review internal/api
/review cmd/dot

# Focus on specific concerns
/review security
/review tests
```

### Too Many Issues

Prioritize effectively:
1. Fix all CRITICAL issues
2. Group related HIGH issues
3. Create separate tasks for MEDIUM issues
4. Defer LOW issues

### False Positives

If a finding is incorrect:
1. Document why it's a false positive
2. Consider adding clarifying comments
3. Update review criteria if pattern is valid

## Support

For questions or issues with the review system:
1. Check this README
2. Review the command documentation: `.cursor/commands/review.md`
3. Examine the template: `reviews/TEMPLATE-code-review.md`
4. Consult project constitutional principles

## Version

Review System Version: 1.0.0
Last Updated: 2025-10-06
Compatible with: dot CLI project v0.0.x

